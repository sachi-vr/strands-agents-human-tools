import cv2
import os
import io
import PIL.Image
import lmstudio as lms
from strands import Agent
from strands.models.litellm import LiteLLMModel
from strands.types.content import Message
from strands.hooks import HookProvider, HookRegistry
from strands.hooks.events import BeforeToolCallEvent, AfterToolCallEvent
import time
from strands import tool
import mss

def get_current_datetime() -> str:
    """Get the current date and time."""
    return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

def human_screen_capture(resizeRatio:float=0.2) -> bytes:
    """Montor what the human is doing in PC screen."""

    with mss.mss() as sct:
        # å…¨ç”»é¢ã‚­ãƒ£ãƒ—ãƒãƒ£
        monitor = sct.monitors[0]  # 0ã¯å…¨ãƒ¢ãƒ‹ã‚¿ã€1ã¯ä¸»ãƒ¢ãƒ‹ã‚¿
        screenshot = sct.grab(monitor)
        # mssã®ScreenShotã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’Pillowã®Imageã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        img = PIL.Image.frombytes("RGB", screenshot.size, screenshot.rgb)
        new_size = (int(img.width * resizeRatio), int(img.height * resizeRatio)) # å¹…ã¨é«˜ã•ã‚’50%ã«ãƒªã‚µã‚¤ã‚º
        _resampling = getattr(PIL.Image, 'Resampling', PIL.Image)
        img_resized = img.resize(new_size, _resampling.LANCZOS)
        buffer = io.BytesIO()
        img_resized.save(buffer, format='PNG', optimize=True, compress_level=9)
        # Reset the buffer position to the beginning
        buffer.seek(0)
        return buffer.getvalue()


def human_webcam_capture() ->  bytes:
    """Monitor the human facial expressions with a webcam."""

    # Open the webcam
    cap = cv2.VideoCapture(0)
    # Read a frame from the webcam
    ret, frame = cap.read()
    # Release the webcam
    cap.release()
    # Convert the frame to a PIL Image
    img = PIL.Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    buffer = io.BytesIO()
    img.save(buffer, format='PNG', optimize=True, compress_level=9)
    # Reset the buffer position to the beginning
    buffer.seek(0)
    return buffer.getvalue()

class ToolCallLimiter(HookProvider):
    """Limits the number of tool calls per agent invocation."""

    def __init__(self, max_tool_calls: int = 3):
        self.max_tool_calls = max_tool_calls
        self.tool_call_count = 0

    def register_hooks(self, registry: HookRegistry) -> None:
        registry.add_callback(BeforeToolCallEvent, self.check_limit)
        registry.add_callback(AfterToolCallEvent, self.count_call)

    def check_limit(self, event: BeforeToolCallEvent) -> None:
        if self.tool_call_count >= self.max_tool_calls:
            event.cancel_tool = f"Tool call limit ({self.max_tool_calls}) reached"
            print(f"âš ï¸ Tool call cancelled: limit of {self.max_tool_calls} reached")

    def count_call(self, event: AfterToolCallEvent) -> None:
        self.tool_call_count += 1
        print(f"ğŸ”§ Tool call {self.tool_call_count}/{self.max_tool_calls}")

    def reset(self) -> None:
        """Reset the counter for a new agent invocation."""
        self.tool_call_count = 0

import pyttsx3
@tool
def speak(text:str) -> bool:
    """Speak a text string using the text-to-speech engine. The human can hear it."""
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()
    return True

def decide_capture_mode(user_instruction: str, model: LiteLLMModel, system_prompt_prefix: str) -> str:
    """Decide capture mode based on the user's instruction.
    Returns one of: 'webcam_capture', 'screen_capture', 'alternate'."""
    prompt = (
        "ã‚ãªãŸã¯ã‚·ã‚¹ãƒ†ãƒ è¨­å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚æ¬¡ã®æŒ‡ç¤ºæ–‡ã‹ã‚‰ã€"
        "äººé–“ã®ç›£è¦–ã«æœ€é©ãªã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰ã‚’1ã¤ã ã‘é¸ã‚“ã§ãã ã•ã„ã€‚"
        "å¿…ãšä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’è¿”ã—ã¦ãã ã•ã„:\n"
        "  - webcam_capture(Webã‚«ãƒ¡ãƒ©)\n"
        "  - screen_capture(ç”»é¢ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ)\n"
        "  - alternate(ã‚«ãƒ¡ãƒ©ã¨ç”»é¢ã®äº¤äº’)\n"
        "æ‚©ã‚€å ´åˆã¯ã€'alternate'ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚\n"
        "ç†ç”±ã‚„ä½™åˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚\n\n"
        f"æŒ‡ç¤ºæ–‡:\n{user_instruction}"
    )
    agent = Agent(model=model, system_prompt=prompt, messages=[Message(role='user', content=[{'text': user_instruction}])])
    try:
        res = agent()
        res_text = str(res).strip().lower()
    except Exception as e:
        print("Warning: mode decision agent failed:", e)
        res_text = ""
    if "webcam" in res_text or "ã‚«ãƒ¡ãƒ©" in res_text:
        return "webcam_capture"
    if "screen" in res_text or "ã‚¹ã‚¯ãƒªãƒ¼ãƒ³" in res_text:
        return "screen_capture"
    if "alternate" in res_text or "äº¤äº’" in res_text:
        return "alternate"
    # fallback to interactive prompt
    return "alternate"


import logging
#logging.getLogger("strands").setLevel(logging.DEBUG)
#logging.basicConfig(
#    format="%(levelname)s | %(name)s | %(message)s", 
#    handlers=[logging.StreamHandler()]
#)
    
def main():
    # pythonã®lmstudioãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    modelstr:str="qwen/qwen3-vl-8b"
    model = lms.llm(modelstr, ttl=180)
    
    all_loaded_models = lms.list_loaded_models()
    print("Loaded models:", all_loaded_models)
    
    # LiteLLMç”¨ã®LM Studioè¨­å®šã®ç’°å¢ƒå¤‰æ•°
    os.environ["OPENAI_API_BASE"] = "http://localhost:1234/v1"
    os.environ["OPENAI_API_KEY"] = "lm-studio"  # ä»»æ„ã®æ–‡å­—åˆ—ï¼ˆLM Studioã¯ç„¡è¦–ï¼‰
    
    # LM Studio ã® OpenAI äº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æŒ‡å®š
    # ãƒ¢ãƒ‡ãƒ«åã«lm_studio/ãŒä»˜ã
    litellm_model = LiteLLMModel(model_id="lm_studio/"+modelstr)
    
    userorder:str=input("æŒ‡ç¤ºã‚’å…¥åŠ›:").strip()
    print("----")
    systemp:str="æŒ‡ç¤º: "+userorder
    print(systemp)
    previous_status="ä»Šã®çŠ¶æ³: é–‹å§‹çŠ¶æ…‹"
    loopcnt=0
    
    mode = decide_capture_mode(userorder, litellm_model, systemp)
    print("é¸æŠã•ã‚ŒãŸã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰:", mode)
    
    # Tool call limiter (max 3 tool calls per loop iteration)
    tool_limiter = ToolCallLimiter(max_tool_calls=1)
    
    # Initialize messages once so history is preserved; exclude image elements
    messages: list[Message] = [
        Message(
            role="assistant",
            content=[{ "text": f"{previous_status}" }]
        )
    ]
    
    while True:
        loopcnt += 1
        print("\n---- loop "+str(loopcnt)+" -----")
        # Reset tool call counter for each loop iteration
        tool_limiter.reset()
        # capture according to selected mode
        try:
            if mode == "webcam_capture":
                source_bytes = human_webcam_capture()
                source_str:str = "webcam"
            elif mode == "screen_capture":
                source_bytes = human_screen_capture()
                source_str:str = "screen"
            else:  # alternate
                if loopcnt % 2 != 0:
                    source_bytes = human_webcam_capture()
                    source_str:str = "webcam"
                else:
                    source_bytes = human_screen_capture()
                    source_str:str = "screen"
        except Exception as e:
            print("Warning: capture failed, falling back to screen capture:", e)
            source_bytes = human_screen_capture()
    
        user_msg = Message(
            role="user",
            content=[
                {
                    "text": f"""{ get_current_datetime() }ç¾åœ¨ã®{ source_str }çŠ¶æ³ã§ã™ã€‚"""
                },
                {
                    "image": {
                        "format": "png",
                        "source": {"bytes": source_bytes}
                    }
                }
            ]
        )
        messages.append(user_msg)
    
        agent = Agent(model=litellm_model, system_prompt=systemp, messages=messages, tools=[speak], hooks=[tool_limiter])
        result = agent()
        previous_status = str(result)
    
        # messagesã¯å‚ç…§æ¸¡ã—ãªã®ã§ã€ã™ã§ã«æ›´æ–°ã•ã‚Œã¦ã„ãŸ
        #messages.append(Message(role="assistant", content=[{"text": previous_status}]))
        #print("\n----- previous_status -----")
        #print(previous_status)
        newmessages = []
        for m in messages[-10:]:
            newrole=m.get("role","unknown")
            newcontent=m.get("content", [{ "text": "unkowntext1" }])
            newcont0=newcontent[0]
            newmessages.append(Message(role=newrole, content=[newcont0]))
        messages = newmessages
        import pprint
        print("---- messages ----")
        pprint.pprint(messages)

if __name__ == "__main__":
    main()